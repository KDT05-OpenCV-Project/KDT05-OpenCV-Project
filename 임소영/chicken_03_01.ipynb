{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-27T01:09:13.003455Z",
     "start_time": "2024-03-27T01:09:12.986407Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import os\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import torchvision.transforms as transforms\n",
    "from torchinfo import summary\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 이미지 전처리 및 dataset 생성"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a33d29ba4ad063ad"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "preprocessing = transforms.Compose([\n",
    "    transforms.Resize(size = (150, 150)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T01:09:13.081462Z",
     "start_time": "2024-03-27T01:09:13.074152Z"
    }
   },
   "id": "e17ee54c4cb3f9e0",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "file_dir = './image'\n",
    "imgDS = ImageFolder(root = file_dir, transform = preprocessing)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T01:09:13.112700Z",
     "start_time": "2024-03-27T01:09:13.095002Z"
    }
   },
   "id": "efd209e974cba687",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['chicken', 'poodle'] {'chicken': 0, 'poodle': 1}\n"
     ]
    }
   ],
   "source": [
    "print(imgDS.classes, imgDS.class_to_idx)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T01:09:13.144085Z",
     "start_time": "2024-03-27T01:09:13.133521Z"
    }
   },
   "id": "d804ff0cf7a24ca9",
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[('./image\\\\chicken\\\\Crispy Chicken-Test (1).jpeg', 0),\n ('./image\\\\chicken\\\\Crispy Chicken-Test (2).jpeg', 0),\n ('./image\\\\chicken\\\\Crispy Chicken-Test (35).jpeg', 0),\n ('./image\\\\chicken\\\\Crispy Chicken-Test (5).jpeg', 0),\n ('./image\\\\chicken\\\\Crispy Chicken-Test (6).jpeg', 0)]"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgDS.imgs[:5]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T01:09:13.159708Z",
     "start_time": "2024-03-27T01:09:13.150342Z"
    }
   },
   "id": "d73eab3edd3a2e62",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torchvision.datasets.folder.ImageFolder'>\n"
     ]
    }
   ],
   "source": [
    "print(type(imgDS))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T01:09:13.174916Z",
     "start_time": "2024-03-27T01:09:13.168339Z"
    }
   },
   "id": "2c749be65cfd435b",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# count = 1\n",
    "# for img, label in imgDS:\n",
    "#     # print(label)\n",
    "#     if label == 1:\n",
    "#         break\n",
    "#     count += 1\n",
    "# print(count)\n",
    "# # chicken : 0 (200)   poodle :  (190)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T01:09:13.221825Z",
     "start_time": "2024-03-27T01:09:13.214518Z"
    }
   },
   "id": "c9eaec88a1bc1aef",
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T01:09:13.237441Z",
     "start_time": "2024-03-27T01:09:13.234272Z"
    }
   },
   "id": "b59df4c007a66dd8",
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "343 49 98\n"
     ]
    }
   ],
   "source": [
    "# dataset에서 train, valid, test를 나누어보자\n",
    "seed_gen = torch.Generator().manual_seed(42)\n",
    "tr, val, ts = 0.7,0.1,0.2\n",
    "trainDS, validDS, testDS = random_split(imgDS, [tr, val, ts], generator=seed_gen)\n",
    "print(len(trainDS), len(validDS), len(testDS))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T01:09:13.268514Z",
     "start_time": "2024-03-27T01:09:13.251865Z"
    }
   },
   "id": "98fd33f8b63c543e",
   "execution_count": 28
  },
  {
   "cell_type": "markdown",
   "source": [
    "# dataloader 생성"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5d4ce0fffd492974"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35 5 10\n"
     ]
    }
   ],
   "source": [
    "# 각 분류별로 dataloader를 생성해보자\n",
    "batch_size = 10\n",
    "train_dl = DataLoader(trainDS, batch_size=batch_size, shuffle=True)\n",
    "valid_dl = DataLoader(validDS, batch_size=batch_size, shuffle=True)\n",
    "test_dl = DataLoader(testDS, batch_size = batch_size, shuffle=True)\n",
    "print(len(train_dl), len(valid_dl), len(test_dl))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T01:09:13.299763Z",
     "start_time": "2024-03-27T01:09:13.286113Z"
    }
   },
   "id": "59e1f4ccb4007105",
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# chicken_dl = DataLoader(dataset = imgDS)\n",
    "# for (image, label) in chicken_dl:\n",
    "#         print(image.shape, label)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T01:09:13.315710Z",
     "start_time": "2024-03-27T01:09:13.310227Z"
    }
   },
   "id": "445c37c5db7a19b1",
   "execution_count": 30
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 전이학습 기릿"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8fa60e34acff472c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 모델 인스턴스 생성 : 사전 학습된 모델 로딩 \n",
    "# => 가중치를 조절해보자!\n",
    "res_model = models.resnet18()\n",
    "\n",
    "# 전결합층 변경\n",
    "res_model.fc = nn.Linear(in_features = 512, out_features = 1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T01:09:13.504068Z",
     "start_time": "2024-03-27T01:09:13.342301Z"
    }
   },
   "id": "3102e3009c7f3afa",
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=512, out_features=1, bias=True)\n)"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T01:09:13.519750Z",
     "start_time": "2024-03-27T01:09:13.506130Z"
    }
   },
   "id": "ec390f5069115569",
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# summary(res_model, input_size = (1, 3, 150, 150))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T01:09:13.535311Z",
     "start_time": "2024-03-27T01:09:13.520748Z"
    }
   },
   "id": "88e54d24a4dab371",
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 모델의 합성곱층 가중치 고정\n",
    "for param in res_model.parameters(): \n",
    "    param.requires_grad = False\n",
    "for param in res_model.fc.parameters():   # 완전 연결층은 학습\n",
    "    param.requires_grad = True\n",
    "\n",
    "# print(res_model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T01:09:13.550948Z",
     "start_time": "2024-03-27T01:09:13.537461Z"
    }
   },
   "id": "c39f970926904632",
   "execution_count": 34
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 학습, 검증, 테스트 함수 정의"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e5cdb8de5e2cfc7e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(res_model.fc.parameters(), lr=0.01)\n",
    "cost = torch.nn.BCELoss() # 손실함수 정의"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T01:09:13.566856Z",
     "start_time": "2024-03-27T01:09:13.555108Z"
    }
   },
   "id": "6089613018986324",
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torchmetrics.functional as metrics\n",
    "\n",
    "def training(dataloader):\n",
    "    res_model.train()\n",
    "    loss_list = []\n",
    "    acc_list = []\n",
    "    precision_list = []\n",
    "    recall_list = []\n",
    "    f1score_list = []\n",
    "    for image, label in dataloader:\n",
    "        # 학습\n",
    "        pre_label = res_model(image)\n",
    "        pre_label = F.sigmoid(pre_label)\n",
    "        \n",
    "        # 여기서 활성함수 나온것을 그대로 써도 될까? 아님 1과 0으로 바꿔야할까??\n",
    "        \n",
    "        pre_label = pre_label.squeeze()\n",
    "        # print(label.shape, pre_label.shape)\n",
    "        # print(label, pre_label, sep = '\\n\\n')\n",
    "        \n",
    "        # 손실계산\n",
    "        train_loss = cost(pre_label, label.float())\n",
    "        # train_loss = cost(pre_label, label)\n",
    "        \n",
    "        # w,b 업데이트\n",
    "        optimizer.zero_grad()\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # 정확도\n",
    "        acc = metrics.accuracy(pre_label, label, task = 'binary') \n",
    "        precision = metrics.precision(pre_label, label, task = 'binary')\n",
    "        recall = metrics.recall(pre_label, label, task = 'binary')\n",
    "        f1score = metrics.f1_score(pre_label, label, task = 'binary')\n",
    "        loss_list.append(train_loss)\n",
    "        acc_list.append(acc)\n",
    "        precision_list.append(precision)\n",
    "        recall_list.append(recall)\n",
    "        f1score_list.append(f1score)\n",
    "    total_loss = sum(loss_list) / len(loss_list)\n",
    "    total_acc = sum(acc_list) / len(acc_list)\n",
    "    total_precision = sum(precision_list) / len(precision_list)\n",
    "    total_recall = sum(recall_list)/len(recall_list)\n",
    "    total_f1score = sum(f1score_list) / len(f1score_list)\n",
    "    # print(f\"[TOTAL Train Loss] ==> {total_loss}\")\n",
    "    # print(f\"ACC : {total_acc}  Precision : {total_precision}  Recall : {total_recall} F1score : {total_f1score}\")\n",
    "    return total_loss, total_acc, total_precision, total_recall, total_f1score\n",
    "\n",
    "# training(train_dl)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T01:09:13.582580Z",
     "start_time": "2024-03-27T01:09:13.568986Z"
    }
   },
   "id": "bc2f791c08c3aaa9",
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def valid_testing(dataloader):\n",
    "    res_model.eval()\n",
    "    loss_list = []\n",
    "    acc_list = []\n",
    "    precision_list = []\n",
    "    recall_list = []\n",
    "    f1score_list = []\n",
    "    for image, label in dataloader:\n",
    "        # 학습\n",
    "        pre_label = res_model(image)\n",
    "        pre_label = F.sigmoid(pre_label)\n",
    "\n",
    "        pre_label = pre_label.squeeze()\n",
    "        # print(label.shape, pre_label.shape)\n",
    "        # print(label, pre_label, sep = '\\n\\n')\n",
    "        \n",
    "        # 손실계산\n",
    "        valid_loss = cost(pre_label, label.float())\n",
    "        # train_loss = cost(pre_label, label)\n",
    "        \n",
    "        # 정확도\n",
    "        acc = metrics.accuracy(pre_label, label, task = 'binary') \n",
    "        precision = metrics.precision(pre_label, label, task = 'binary')\n",
    "        recall = metrics.recall(pre_label, label, task = 'binary')\n",
    "        f1score = metrics.f1_score(pre_label, label, task = 'binary')\n",
    "        loss_list.append(valid_loss)\n",
    "        acc_list.append(acc)\n",
    "        precision_list.append(precision)\n",
    "        recall_list.append(recall)\n",
    "        f1score_list.append(f1score)\n",
    "    total_loss = sum(loss_list) / len(loss_list)\n",
    "    total_acc = sum(acc_list) / len(acc_list)\n",
    "    total_precision = sum(precision_list) / len(precision_list)\n",
    "    total_recall = sum(recall_list)/len(recall_list)\n",
    "    total_f1score = sum(f1score_list) / len(f1score_list)\n",
    "    # print(f\"[TOTAL Train Loss] ==> {total_loss}\")\n",
    "    # print(f\"ACC : {total_acc}  Precision : {total_precision}  Recall : {total_recall} F1score : {total_f1score}\")\n",
    "    return total_loss, total_acc, total_precision, total_recall, total_f1score\n",
    "\n",
    "# valid_testing(valid_dl)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T01:09:13.598404Z",
     "start_time": "2024-03-27T01:09:13.584630Z"
    }
   },
   "id": "aec39b6e1c7643a5",
   "execution_count": 37
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 학습 진행해보자"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e9372889093d2d5b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "## 학습 중 모델 저장 관련 변수\n",
    "dir = './model/'\n",
    "filename = dir + \"best_model.pth\"\n",
    "\n",
    "import os\n",
    "if not os.path.exists(dir) :\n",
    "    os.mkdir(dir)       # 하위 폴더만 생성 증, data 폴더는 이미 존재해야 함\n",
    "    # os.makedirs(dir)    # 존재하지 않는 상위 폴더부터 생성"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T01:09:13.614023Z",
     "start_time": "2024-03-27T01:09:13.600499Z"
    }
   },
   "id": "143b06f5ccc4efd8",
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "epoch_num = 100\n",
    "training_list = [[], [], [], [], []]\n",
    "validing_list = [[], [], [], [], []]\n",
    "# loss, acc, prec, rec, f1_score\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones = [0, epoch_num], gamma = 0.5)\n",
    "# milestones => 어떤 에포크 구간에서 학습률을 조정할지 나타내는거\n",
    "\n",
    "# 모델 저장 관련 변수\n",
    "save_score_point = 5"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T01:09:13.629756Z",
     "start_time": "2024-03-27T01:09:13.616018Z"
    }
   },
   "id": "13005c607d8835c8",
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6352, grad_fn=<DivBackward0>) tensor(0.6648) tensor(0.6566) tensor(0.6523) tensor(0.6029)\n",
      "epo => 0  학습중\n",
      "epo => 0  검증중\n",
      "  모 델 저 장 완 료\n",
      "tensor(0.5133, grad_fn=<DivBackward0>) tensor(0.7486) tensor(0.7649) tensor(0.7880) tensor(0.7445)\n",
      "epo => 1  학습중\n",
      "epo => 1  검증중\n",
      "  모 델 저 장 완 료\n",
      "tensor(0.4639, grad_fn=<DivBackward0>) tensor(0.8143) tensor(0.8193) tensor(0.8500) tensor(0.8058)\n",
      "epo => 2  학습중\n",
      "epo => 2  검증중\n",
      "  모 델 저 장 완 료\n",
      "tensor(0.4911, grad_fn=<DivBackward0>) tensor(0.7676) tensor(0.7564) tensor(0.8091) tensor(0.7433)\n",
      "epo => 3  학습중\n",
      "epo => 3  검증중\n",
      "  모 델 저 장 완 료\n",
      "tensor(0.6587, grad_fn=<DivBackward0>) tensor(0.6933) tensor(0.7452) tensor(0.7116) tensor(0.6521)\n",
      "epo => 4  학습중\n",
      "epo => 4  검증중\n",
      "  모 델 저 장 완 료\n",
      "tensor(0.4147, grad_fn=<DivBackward0>) tensor(0.8229) tensor(0.8128) tensor(0.8980) tensor(0.8281)\n",
      "epo => 5  학습중\n",
      "epo => 5  검증중\n",
      "  모 델 저 장 완 료\n",
      "tensor(0.3945, grad_fn=<DivBackward0>) tensor(0.8314) tensor(0.8256) tensor(0.8724) tensor(0.8260)\n",
      "epo => 6  학습중\n",
      "epo => 6  검증중\n",
      "  모 델 저 장 완 료\n",
      "tensor(0.4685, grad_fn=<DivBackward0>) tensor(0.7705) tensor(0.7906) tensor(0.8258) tensor(0.7623)\n",
      "epo => 7  학습중\n",
      "epo => 7  검증중\n",
      "  모 델 저 장 완 료\n",
      "tensor(0.3974, grad_fn=<DivBackward0>) tensor(0.8257) tensor(0.8837) tensor(0.7994) tensor(0.8097)\n",
      "epo => 8  학습중\n",
      "epo => 8  검증중\n",
      "  모 델 저 장 완 료\n",
      "tensor(0.3659, grad_fn=<DivBackward0>) tensor(0.8505) tensor(0.8698) tensor(0.8663) tensor(0.8457)\n",
      "epo => 9  학습중\n",
      "epo => 9  검증중\n",
      "  모 델 저 장 완 료\n",
      "tensor(0.3832, grad_fn=<DivBackward0>) tensor(0.8400) tensor(0.8415) tensor(0.8736) tensor(0.8284)\n",
      "epo => 10  학습중\n",
      "epo => 10  검증중\n",
      "  모 델 저 장 완 료\n",
      "tensor(0.3428, grad_fn=<DivBackward0>) tensor(0.8686) tensor(0.8814) tensor(0.8852) tensor(0.8645)\n",
      "epo => 11  학습중\n",
      "epo => 11  검증중\n",
      "  모 델 저 장 완 료\n",
      "tensor(0.3953, grad_fn=<DivBackward0>) tensor(0.8162) tensor(0.8282) tensor(0.8655) tensor(0.8067)\n",
      "epo => 12  학습중\n",
      "epo => 12  검증중\n",
      "  모 델 저 장 완 료\n",
      "tensor(0.3180, grad_fn=<DivBackward0>) tensor(0.8705) tensor(0.8698) tensor(0.8881) tensor(0.8661)\n",
      "epo => 13  학습중\n",
      "epo => 13  검증중\n",
      "  모 델 저 장 완 료\n",
      "tensor(0.4090, grad_fn=<DivBackward0>) tensor(0.8190) tensor(0.8163) tensor(0.8285) tensor(0.7911)\n",
      "epo => 14  학습중\n",
      "epo => 14  검증중\n",
      "  모 델 저 장 완 료\n",
      "tensor(0.5039, grad_fn=<DivBackward0>) tensor(0.7429) tensor(0.8069) tensor(0.7386) tensor(0.7037)\n",
      "epo => 15  학습중\n",
      "epo => 15  검증중\n",
      "  모 델 저 장 완 료\n",
      "tensor(0.4219, grad_fn=<DivBackward0>) tensor(0.8019) tensor(0.8219) tensor(0.8495) tensor(0.7899)\n",
      "epo => 16  학습중\n",
      "epo => 16  검증중\n",
      "  모 델 저 장 완 료\n",
      "tensor(0.3353, grad_fn=<DivBackward0>) tensor(0.8486) tensor(0.8561) tensor(0.8826) tensor(0.8430)\n",
      "epo => 17  학습중\n",
      "epo => 17  검증중\n",
      "  모 델 저 장 완 료\n",
      "tensor(0.3438, grad_fn=<DivBackward0>) tensor(0.8552) tensor(0.8906) tensor(0.8621) tensor(0.8497)\n",
      "epo => 18  학습중\n",
      "epo => 18  검증중\n",
      "  모 델 저 장 완 료\n",
      "tensor(0.3409, grad_fn=<DivBackward0>) tensor(0.8714) tensor(0.9059) tensor(0.8695) tensor(0.8695)\n",
      "epo => 19  학습중\n",
      "epo => 19  검증중\n",
      "  모 델 저 장 완 료\n",
      "tensor(0.3141, grad_fn=<DivBackward0>) tensor(0.8629) tensor(0.8569) tensor(0.8997) tensor(0.8564)\n",
      "epo => 20  학습중\n",
      "epo => 20  검증중\n",
      "  모 델 저 장 완 료\n",
      "tensor(0.3480, grad_fn=<DivBackward0>) tensor(0.8543) tensor(0.8704) tensor(0.8607) tensor(0.8372)\n",
      "epo => 21  학습중\n",
      "epo => 21  검증중\n",
      "  모 델 저 장 완 료\n",
      "tensor(0.3398, grad_fn=<DivBackward0>) tensor(0.8552) tensor(0.8371) tensor(0.8861) tensor(0.8376)\n",
      "epo => 22  학습중\n",
      "epo => 22  검증중\n",
      "  모 델 저 장 완 료\n",
      "tensor(0.3647, grad_fn=<DivBackward0>) tensor(0.8314) tensor(0.8594) tensor(0.8387) tensor(0.8093)\n",
      "epo => 23  학습중\n",
      "epo => 23  검증중\n",
      "  모 델 저 장 완 료\n",
      "tensor(0.3488, grad_fn=<DivBackward0>) tensor(0.8600) tensor(0.8929) tensor(0.8643) tensor(0.8535)\n",
      "epo => 24  학습중\n",
      "epo => 24  검증중\n",
      "  모 델 저 장 완 료\n",
      "tensor(0.4081, grad_fn=<DivBackward0>) tensor(0.8600) tensor(0.8728) tensor(0.8949) tensor(0.8526)\n",
      "epo => 25  학습중\n",
      "epo => 25  검증중\n",
      "  모 델 저 장 완 료\n",
      "tensor(0.4735, grad_fn=<DivBackward0>) tensor(0.7800) tensor(0.8021) tensor(0.7658) tensor(0.7352)\n",
      "epo => 26  학습중\n",
      "epo => 26  검증중\n",
      "  모 델 저 장 완 료\n",
      "tensor(0.3502, grad_fn=<DivBackward0>) tensor(0.8610) tensor(0.8807) tensor(0.8628) tensor(0.8511)\n",
      "epo => 27  학습중\n",
      "epo => 27  검증중\n",
      "  모 델 저 장 완 료\n",
      "tensor(0.3373, grad_fn=<DivBackward0>) tensor(0.8305) tensor(0.8610) tensor(0.8491) tensor(0.8168)\n",
      "epo => 28  학습중\n",
      "epo => 28  검증중\n",
      "  모 델 저 장 완 료\n",
      "tensor(0.2888, grad_fn=<DivBackward0>) tensor(0.8600) tensor(0.8781) tensor(0.8399) tensor(0.8347)\n",
      "epo => 29  학습중\n",
      "epo => 29  검증중\n",
      "  모 델 저 장 완 료\n",
      "tensor(0.2680, grad_fn=<DivBackward0>) tensor(0.9086) tensor(0.8930) tensor(0.9388) tensor(0.9018)\n",
      "epo => 30  학습중\n",
      "epo => 30  검증중\n",
      "  모 델 저 장 완 료\n",
      "tensor(0.3176, grad_fn=<DivBackward0>) tensor(0.8829) tensor(0.9080) tensor(0.8899) tensor(0.8686)\n",
      "epo => 31  학습중\n",
      "epo => 31  검증중\n",
      "  모 델 저 장 완 료\n",
      "tensor(0.3126, grad_fn=<DivBackward0>) tensor(0.8676) tensor(0.8295) tensor(0.8963) tensor(0.8412)\n",
      "epo => 32  학습중\n",
      "epo => 32  검증중\n",
      "  모 델 저 장 완 료\n",
      "tensor(0.3222, grad_fn=<DivBackward0>) tensor(0.8495) tensor(0.8689) tensor(0.8876) tensor(0.8454)\n",
      "epo => 33  학습중\n",
      "epo => 33  검증중\n",
      "  모 델 저 장 완 료\n",
      "tensor(0.2764, grad_fn=<DivBackward0>) tensor(0.8952) tensor(0.8912) tensor(0.9039) tensor(0.8814)\n",
      "epo => 34  학습중\n",
      "epo => 34  검증중\n",
      "  모 델 저 장 완 료\n",
      "tensor(0.2750, grad_fn=<DivBackward0>) tensor(0.8800) tensor(0.9151) tensor(0.8660) tensor(0.8662)\n",
      "epo => 35  학습중\n",
      "epo => 35  검증중\n",
      "  모 델 저 장 완 료\n",
      "tensor(0.3013, grad_fn=<DivBackward0>) tensor(0.9019) tensor(0.9199) tensor(0.9189) tensor(0.9011)\n",
      "epo => 36  학습중\n",
      "epo => 36  검증중\n",
      "  모 델 저 장 완 료\n",
      "tensor(0.3917, grad_fn=<DivBackward0>) tensor(0.8200) tensor(0.8530) tensor(0.8525) tensor(0.8111)\n",
      "epo => 37  학습중\n",
      "epo => 37  검증중\n",
      "  모 델 저 장 완 료\n",
      "tensor(0.2252, grad_fn=<DivBackward0>) tensor(0.9048) tensor(0.9099) tensor(0.9179) tensor(0.9000)\n",
      "epo => 38  학습중\n",
      "epo => 38  검증중\n",
      "  모 델 저 장 완 료\n",
      "tensor(0.3807, grad_fn=<DivBackward0>) tensor(0.8286) tensor(0.8370) tensor(0.8391) tensor(0.8026)\n",
      "epo => 39  학습중\n",
      "epo => 39  검증중\n",
      "  모 델 저 장 완 료\n",
      "tensor(0.2729, grad_fn=<DivBackward0>) tensor(0.8971) tensor(0.9024) tensor(0.9148) tensor(0.8895)\n",
      "epo => 40  학습중\n",
      "epo => 40  검증중\n",
      "  모 델 저 장 완 료\n",
      "tensor(0.2847, grad_fn=<DivBackward0>) tensor(0.9000) tensor(0.9055) tensor(0.9202) tensor(0.8932)\n",
      "epo => 41  학습중\n",
      "epo => 41  검증중\n",
      "  모 델 저 장 완 료\n",
      "tensor(0.3057, grad_fn=<DivBackward0>) tensor(0.8562) tensor(0.8793) tensor(0.8724) tensor(0.8479)\n",
      "epo => 42  학습중\n",
      "epo => 42  검증중\n",
      "  모 델 저 장 완 료\n",
      "tensor(0.2142, grad_fn=<DivBackward0>) tensor(0.9248) tensor(0.9295) tensor(0.9202) tensor(0.9161)\n",
      "epo => 43  학습중\n",
      "epo => 43  검증중\n",
      "  모 델 저 장 완 료\n",
      "tensor(0.2772, grad_fn=<DivBackward0>) tensor(0.8848) tensor(0.8690) tensor(0.8932) tensor(0.8597)\n",
      "epo => 44  학습중\n",
      "epo => 44  검증중\n",
      "  모 델 저 장 완 료\n",
      "tensor(0.3049, grad_fn=<DivBackward0>) tensor(0.8800) tensor(0.9138) tensor(0.8709) tensor(0.8632)\n",
      "epo => 45  학습중\n",
      "epo => 45  검증중\n",
      "  모 델 저 장 완 료\n",
      "tensor(0.3531, grad_fn=<DivBackward0>) tensor(0.8648) tensor(0.9044) tensor(0.8612) tensor(0.8509)\n",
      "epo => 46  학습중\n",
      "epo => 46  검증중\n",
      "  모 델 저 장 완 료\n",
      "tensor(0.2968, grad_fn=<DivBackward0>) tensor(0.8771) tensor(0.8847) tensor(0.9197) tensor(0.8792)\n",
      "epo => 47  학습중\n",
      "epo => 47  검증중\n",
      "  모 델 저 장 완 료\n",
      "tensor(0.2739, grad_fn=<DivBackward0>) tensor(0.8914) tensor(0.9248) tensor(0.8826) tensor(0.8818)\n",
      "epo => 48  학습중\n",
      "epo => 48  검증중\n",
      "  모 델 저 장 완 료\n",
      "tensor(0.2979, grad_fn=<DivBackward0>) tensor(0.8648) tensor(0.8600) tensor(0.9084) tensor(0.8572)\n",
      "epo => 49  학습중\n",
      "epo => 49  검증중\n",
      "  모 델 저 장 완 료\n",
      "tensor(0.2888, grad_fn=<DivBackward0>) tensor(0.8771) tensor(0.8856) tensor(0.9021) tensor(0.8658)\n",
      "epo => 50  학습중\n",
      "epo => 50  검증중\n",
      "  모 델 저 장 완 료\n",
      "tensor(0.3032, grad_fn=<DivBackward0>) tensor(0.8743) tensor(0.8629) tensor(0.9134) tensor(0.8666)\n",
      "epo => 51  학습중\n",
      "epo => 51  검증중\n",
      "  모 델 저 장 완 료\n",
      "tensor(0.2469, grad_fn=<DivBackward0>) tensor(0.9000) tensor(0.9109) tensor(0.9109) tensor(0.8966)\n",
      "epo => 52  학습중\n",
      "epo => 52  검증중\n",
      "  모 델 저 장 완 료\n",
      "tensor(0.2529, grad_fn=<DivBackward0>) tensor(0.8762) tensor(0.8716) tensor(0.8737) tensor(0.8492)\n",
      "epo => 53  학습중\n",
      "epo => 53  검증중\n",
      "  모 델 저 장 완 료\n",
      "tensor(0.2976, grad_fn=<DivBackward0>) tensor(0.8629) tensor(0.8988) tensor(0.8696) tensor(0.8532)\n",
      "epo => 54  학습중\n",
      "epo => 54  검증중\n",
      "  모 델 저 장 완 료\n",
      "tensor(0.1853, grad_fn=<DivBackward0>) tensor(0.9429) tensor(0.9405) tensor(0.9464) tensor(0.9370)\n",
      "epo => 55  학습중\n",
      "epo => 55  검증중\n",
      "  모 델 저 장 완 료\n",
      "tensor(0.3410, grad_fn=<DivBackward0>) tensor(0.8362) tensor(0.8395) tensor(0.8559) tensor(0.8157)\n",
      "epo => 56  학습중\n",
      "epo => 56  검증중\n",
      "  모 델 저 장 완 료\n",
      "tensor(0.2812, grad_fn=<DivBackward0>) tensor(0.8790) tensor(0.8871) tensor(0.9017) tensor(0.8697)\n",
      "epo => 57  학습중\n",
      "epo => 57  검증중\n",
      "  모 델 저 장 완 료\n",
      "tensor(0.2985, grad_fn=<DivBackward0>) tensor(0.8695) tensor(0.8910) tensor(0.8967) tensor(0.8611)\n",
      "epo => 58  학습중\n",
      "epo => 58  검증중\n",
      "  모 델 저 장 완 료\n",
      "tensor(0.2396, grad_fn=<DivBackward0>) tensor(0.9029) tensor(0.8895) tensor(0.9330) tensor(0.8950)\n",
      "epo => 59  학습중\n",
      "epo => 59  검증중\n",
      "  모 델 저 장 완 료\n",
      "tensor(0.2263, grad_fn=<DivBackward0>) tensor(0.9143) tensor(0.9273) tensor(0.9233) tensor(0.9095)\n",
      "epo => 60  학습중\n",
      "epo => 60  검증중\n",
      "  모 델 저 장 완 료\n",
      "tensor(0.2377, grad_fn=<DivBackward0>) tensor(0.8962) tensor(0.9181) tensor(0.8940) tensor(0.8895)\n",
      "epo => 61  학습중\n",
      "epo => 61  검증중\n",
      "  모 델 저 장 완 료\n",
      "tensor(0.2927, grad_fn=<DivBackward0>) tensor(0.9019) tensor(0.9010) tensor(0.9332) tensor(0.9010)\n",
      "epo => 62  학습중\n",
      "epo => 62  검증중\n",
      "  모 델 저 장 완 료\n",
      "tensor(0.2534, grad_fn=<DivBackward0>) tensor(0.9038) tensor(0.9224) tensor(0.9135) tensor(0.9054)\n",
      "epo => 63  학습중\n",
      "epo => 63  검증중\n",
      "  모 델 저 장 완 료\n",
      "tensor(0.2692, grad_fn=<DivBackward0>) tensor(0.8733) tensor(0.8809) tensor(0.9246) tensor(0.8810)\n",
      "epo => 64  학습중\n",
      "epo => 64  검증중\n",
      "  모 델 저 장 완 료\n",
      "tensor(0.2583, grad_fn=<DivBackward0>) tensor(0.9086) tensor(0.9259) tensor(0.9203) tensor(0.9078)\n",
      "epo => 65  학습중\n",
      "epo => 65  검증중\n",
      "  모 델 저 장 완 료\n",
      "tensor(0.2539, grad_fn=<DivBackward0>) tensor(0.8886) tensor(0.8922) tensor(0.9147) tensor(0.8794)\n",
      "epo => 66  학습중\n",
      "epo => 66  검증중\n",
      "  모 델 저 장 완 료\n",
      "tensor(0.2689, grad_fn=<DivBackward0>) tensor(0.8990) tensor(0.8865) tensor(0.9277) tensor(0.8784)\n",
      "epo => 67  학습중\n",
      "epo => 67  검증중\n",
      "  모 델 저 장 완 료\n",
      "tensor(0.2334, grad_fn=<DivBackward0>) tensor(0.8886) tensor(0.8819) tensor(0.9037) tensor(0.8770)\n",
      "epo => 68  학습중\n",
      "epo => 68  검증중\n",
      "  모 델 저 장 완 료\n",
      "tensor(0.2435, grad_fn=<DivBackward0>) tensor(0.8971) tensor(0.8773) tensor(0.9316) tensor(0.8872)\n",
      "epo => 69  학습중\n",
      "epo => 69  검증중\n",
      "  모 델 저 장 완 료\n",
      "tensor(0.2455, grad_fn=<DivBackward0>) tensor(0.9143) tensor(0.9285) tensor(0.9299) tensor(0.9121)\n",
      "epo => 70  학습중\n",
      "epo => 70  검증중\n",
      "  모 델 저 장 완 료\n",
      "tensor(0.2511, grad_fn=<DivBackward0>) tensor(0.8971) tensor(0.8839) tensor(0.9294) tensor(0.8865)\n",
      "epo => 71  학습중\n",
      "epo => 71  검증중\n",
      "  모 델 저 장 완 료\n",
      "tensor(0.2314, grad_fn=<DivBackward0>) tensor(0.9000) tensor(0.9299) tensor(0.8579) tensor(0.8744)\n",
      "epo => 72  학습중\n",
      "epo => 72  검증중\n",
      "  모 델 저 장 완 료\n",
      "tensor(0.2652, grad_fn=<DivBackward0>) tensor(0.9029) tensor(0.9038) tensor(0.9297) tensor(0.8991)\n",
      "epo => 73  학습중\n",
      "epo => 73  검증중\n",
      "  모 델 저 장 완 료\n",
      "tensor(0.2365, grad_fn=<DivBackward0>) tensor(0.9095) tensor(0.9231) tensor(0.9298) tensor(0.9085)\n",
      "epo => 74  학습중\n",
      "epo => 74  검증중\n",
      "  모 델 저 장 완 료\n",
      "tensor(0.2973, grad_fn=<DivBackward0>) tensor(0.8505) tensor(0.8505) tensor(0.8687) tensor(0.8309)\n",
      "epo => 75  학습중\n",
      "epo => 75  검증중\n",
      "  모 델 저 장 완 료\n",
      "tensor(0.2804, grad_fn=<DivBackward0>) tensor(0.8657) tensor(0.8664) tensor(0.9173) tensor(0.8596)\n",
      "epo => 76  학습중\n",
      "epo => 76  검증중\n",
      "  모 델 저 장 완 료\n",
      "tensor(0.2759, grad_fn=<DivBackward0>) tensor(0.8933) tensor(0.8924) tensor(0.9313) tensor(0.8896)\n",
      "epo => 77  학습중\n",
      "epo => 77  검증중\n",
      "  모 델 저 장 완 료\n",
      "tensor(0.2754, grad_fn=<DivBackward0>) tensor(0.8714) tensor(0.8799) tensor(0.9178) tensor(0.8744)\n",
      "epo => 78  학습중\n",
      "epo => 78  검증중\n",
      "  모 델 저 장 완 료\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[40], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epo \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(epoch_num):\n\u001B[0;32m      2\u001B[0m     \u001B[38;5;66;03m# 학습\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m     loss, acc, prec, rec, f1 \u001B[38;5;241m=\u001B[39m \u001B[43mtraining\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_dl\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      4\u001B[0m     \u001B[38;5;28mprint\u001B[39m(loss, acc, prec, rec, f1)\n\u001B[0;32m      5\u001B[0m     training_list[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mappend(loss\u001B[38;5;241m.\u001B[39mitem())\n",
      "Cell \u001B[1;32mIn[36], line 10\u001B[0m, in \u001B[0;36mtraining\u001B[1;34m(dataloader)\u001B[0m\n\u001B[0;32m      8\u001B[0m recall_list \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m      9\u001B[0m f1score_list \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m---> 10\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m image, label \u001B[38;5;129;01min\u001B[39;00m dataloader:\n\u001B[0;32m     11\u001B[0m     \u001B[38;5;66;03m# 학습\u001B[39;00m\n\u001B[0;32m     12\u001B[0m     pre_label \u001B[38;5;241m=\u001B[39m res_model(image)\n\u001B[0;32m     13\u001B[0m     pre_label \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39msigmoid(pre_label)\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\envs\\Torch_PY38\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    628\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    629\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[0;32m    630\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[1;32m--> 631\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    632\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    633\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    634\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    635\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\envs\\Torch_PY38\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    673\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    674\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m--> 675\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m    676\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[0;32m    677\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\envs\\Torch_PY38\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[1;34m(self, possibly_batched_index)\u001B[0m\n\u001B[0;32m     47\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mauto_collation:\n\u001B[0;32m     48\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__getitems__\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__:\n\u001B[1;32m---> 49\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__getitems__\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpossibly_batched_index\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     51\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\envs\\Torch_PY38\\lib\\site-packages\\torch\\utils\\data\\dataset.py:399\u001B[0m, in \u001B[0;36mSubset.__getitems__\u001B[1;34m(self, indices)\u001B[0m\n\u001B[0;32m    397\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__([\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindices[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m indices])  \u001B[38;5;66;03m# type: ignore[attr-defined]\u001B[39;00m\n\u001B[0;32m    398\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 399\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindices[idx]] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m indices]\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\envs\\Torch_PY38\\lib\\site-packages\\torch\\utils\\data\\dataset.py:399\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    397\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__([\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindices[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m indices])  \u001B[38;5;66;03m# type: ignore[attr-defined]\u001B[39;00m\n\u001B[0;32m    398\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 399\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mindices\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m indices]\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\envs\\Torch_PY38\\lib\\site-packages\\torchvision\\datasets\\folder.py:229\u001B[0m, in \u001B[0;36mDatasetFolder.__getitem__\u001B[1;34m(self, index)\u001B[0m\n\u001B[0;32m    221\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    222\u001B[0m \u001B[38;5;124;03mArgs:\u001B[39;00m\n\u001B[0;32m    223\u001B[0m \u001B[38;5;124;03m    index (int): Index\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    226\u001B[0m \u001B[38;5;124;03m    tuple: (sample, target) where target is class_index of the target class.\u001B[39;00m\n\u001B[0;32m    227\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    228\u001B[0m path, target \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msamples[index]\n\u001B[1;32m--> 229\u001B[0m sample \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    230\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransform \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    231\u001B[0m     sample \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransform(sample)\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\envs\\Torch_PY38\\lib\\site-packages\\torchvision\\datasets\\folder.py:268\u001B[0m, in \u001B[0;36mdefault_loader\u001B[1;34m(path)\u001B[0m\n\u001B[0;32m    266\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m accimage_loader(path)\n\u001B[0;32m    267\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 268\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mpil_loader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\envs\\Torch_PY38\\lib\\site-packages\\torchvision\\datasets\\folder.py:246\u001B[0m, in \u001B[0;36mpil_loader\u001B[1;34m(path)\u001B[0m\n\u001B[0;32m    244\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpil_loader\u001B[39m(path: \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Image\u001B[38;5;241m.\u001B[39mImage:\n\u001B[0;32m    245\u001B[0m     \u001B[38;5;66;03m# open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\u001B[39;00m\n\u001B[1;32m--> 246\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(path, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrb\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[0;32m    247\u001B[0m         img \u001B[38;5;241m=\u001B[39m Image\u001B[38;5;241m.\u001B[39mopen(f)\n\u001B[0;32m    248\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m img\u001B[38;5;241m.\u001B[39mconvert(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRGB\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "for epo in range(epoch_num):\n",
    "    # 학습\n",
    "    loss, acc, prec, rec, f1 = training(train_dl)\n",
    "    print(loss, acc, prec, rec, f1)\n",
    "    training_list[0].append(loss.item())\n",
    "    training_list[1].append(acc.item())\n",
    "    training_list[2].append(prec.item())\n",
    "    training_list[3].append(rec.item())\n",
    "    training_list[4].append(f1.item())\n",
    "    print(f\"epo => {epo}  학습중\")\n",
    "    # 검증\n",
    "    loss, acc, prec, rec, f1 = valid_testing(valid_dl)\n",
    "    validing_list[0].append(loss.item())\n",
    "    validing_list[1].append(acc.item())\n",
    "    validing_list[2].append(prec.item())\n",
    "    validing_list[3].append(rec.item())\n",
    "    validing_list[4].append(f1.item())\n",
    "    print(f\"epo => {epo}  검증중\")\n",
    "    \n",
    "    # 검증 데이터 기준 학습된 모델 저장\n",
    "    if loss < save_score_point:\n",
    "        torch.save(res_model, filename)\n",
    "        print('  모 델 저 장 완 료\\n')\n",
    "    \n",
    "    # 조기종료\n",
    "    \n",
    "    \n",
    "    # 스케줄러\n",
    "    scheduler.step()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T01:34:17.465390Z",
     "start_time": "2024-03-27T01:09:13.631839Z"
    }
   },
   "id": "b6dc627cc7b75c16",
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "epo_list = list(range(0, epoch_num))\n",
    "# print(epo_list)\n",
    "title_list = ['LOSS', 'ACC', 'PRECISION', 'RECALL', 'F1-SCORE']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T01:34:17.470007Z",
     "start_time": "2024-03-27T01:34:17.469007Z"
    }
   },
   "id": "4526433cb4eeafd2",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,5))\n",
    "k=0\n",
    "plt.title(title_list[k])\n",
    "plt.plot(epo_list, training_list[k], label = 'train')\n",
    "plt.plot(epo_list, validing_list[k], label = 'valid')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-27T01:34:17.471099Z"
    }
   },
   "id": "778cdbd7160771a3",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,7))\n",
    "for k in range(1,5):\n",
    "    plt.subplot(2,2,k)\n",
    "    plt.title(title_list[k])\n",
    "    plt.plot(epo_list, training_list[k], label = 'train', color = 'royalblue', alpha = 0.7)\n",
    "    plt.plot(epo_list, validing_list[k], label = 'valid', color = 'tomato')\n",
    "    plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "13763237fede1402",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 예측"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dda7b2e766a30484"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def predicting(dataloader):\n",
    "    res_model.eval()\n",
    "    loss_list = []\n",
    "    acc_list = []\n",
    "    precision_list = []\n",
    "    recall_list = []\n",
    "    f1score_list = []\n",
    "    for image, label in dataloader:\n",
    "        # 학습\n",
    "        pre_label = res_model(image)\n",
    "        pre_label = F.sigmoid(pre_label)\n",
    "\n",
    "        pre_label = pre_label.squeeze()\n",
    "        # print(label.shape, pre_label.shape)\n",
    "        # print(label, pre_label, sep = '\\n\\n')\n",
    "        \n",
    "        # 손실계산\n",
    "        pred_loss = cost(pre_label, label.float())\n",
    "        # train_loss = cost(pre_label, label)\n",
    "        \n",
    "        # 정확도\n",
    "        acc = metrics.accuracy(pre_label, label, task = 'binary') \n",
    "        precision = metrics.precision(pre_label, label, task = 'binary')\n",
    "        recall = metrics.recall(pre_label, label, task = 'binary')\n",
    "        f1score = metrics.f1_score(pre_label, label, task = 'binary')\n",
    "        loss_list.append(pred_loss)\n",
    "        acc_list.append(acc)\n",
    "        precision_list.append(precision)\n",
    "        recall_list.append(recall)\n",
    "        f1score_list.append(f1score)\n",
    "    total_loss = sum(loss_list) / len(loss_list)\n",
    "    total_acc = sum(acc_list) / len(acc_list)\n",
    "    total_precision = sum(precision_list) / len(precision_list)\n",
    "    total_recall = sum(recall_list)/len(recall_list)\n",
    "    total_f1score = sum(f1score_list) / len(f1score_list)\n",
    "    print(f\"[TOTAL Train Loss] ==> {total_loss}\")\n",
    "    print(f\"ACC : {total_acc}  Precision : {total_precision}  Recall : {total_recall} F1score : {total_f1score}\")\n",
    "    return total_loss, total_acc, total_precision, total_recall, total_f1score\n",
    "\n",
    "predicting(test_dl)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-27T01:34:17.474176Z"
    }
   },
   "id": "684e3b1c6a3d7bbf",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-27T01:34:17.474176Z"
    }
   },
   "id": "66ef8b39b5b9d911",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-27T01:34:17.474176Z"
    }
   },
   "id": "94f425a2356a62bc"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
