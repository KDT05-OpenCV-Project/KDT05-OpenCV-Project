{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mathn\\.conda\\envs\\Torch_PY38\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] 지정된 프로시저를 찾을 수 없습니다'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "from torchmetrics.functional.classification import multiclass_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mop', 'mop_dog'] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1] [('./data\\\\mop\\\\1.jpg', 0), ('./data\\\\mop\\\\10.jpg', 0), ('./data\\\\mop\\\\105.jpg', 0), ('./data\\\\mop\\\\112.jpg', 0), ('./data\\\\mop\\\\115.jpg', 0), ('./data\\\\mop\\\\118.jpg', 0), ('./data\\\\mop\\\\121.jpg', 0), ('./data\\\\mop\\\\134.jpg', 0), ('./data\\\\mop\\\\144.jpg', 0), ('./data\\\\mop\\\\150.jpg', 0), ('./data\\\\mop\\\\155.jpg', 0), ('./data\\\\mop\\\\157.jpg', 0), ('./data\\\\mop\\\\163.jpg', 0), ('./data\\\\mop\\\\17.jpg', 0), ('./data\\\\mop\\\\182.jpg', 0), ('./data\\\\mop\\\\184.jpg', 0), ('./data\\\\mop\\\\198.jpg', 0), ('./data\\\\mop\\\\22.jpg', 0), ('./data\\\\mop\\\\23.jpg', 0), ('./data\\\\mop\\\\24.jpg', 0), ('./data\\\\mop\\\\26.jpg', 0), ('./data\\\\mop\\\\27.jpg', 0), ('./data\\\\mop\\\\28.jpg', 0), ('./data\\\\mop\\\\29.jpg', 0), ('./data\\\\mop\\\\30.jpg', 0), ('./data\\\\mop\\\\300.jpg', 0), ('./data\\\\mop\\\\301.jpg', 0), ('./data\\\\mop\\\\302.jpg', 0), ('./data\\\\mop\\\\306.jpg', 0), ('./data\\\\mop\\\\307.jpg', 0), ('./data\\\\mop\\\\308.jpg', 0), ('./data\\\\mop\\\\310.jpg', 0), ('./data\\\\mop\\\\311.jpg', 0), ('./data\\\\mop\\\\312.jpg', 0), ('./data\\\\mop\\\\314.jpg', 0), ('./data\\\\mop\\\\315.jpg', 0), ('./data\\\\mop\\\\317.jpg', 0), ('./data\\\\mop\\\\318.jpg', 0), ('./data\\\\mop\\\\319.jpg', 0), ('./data\\\\mop\\\\320.jpg', 0), ('./data\\\\mop\\\\324.jpg', 0), ('./data\\\\mop\\\\325.jpg', 0), ('./data\\\\mop\\\\326.jpg', 0), ('./data\\\\mop\\\\328.jpg', 0), ('./data\\\\mop\\\\329.jpg', 0), ('./data\\\\mop\\\\330.jpg', 0), ('./data\\\\mop\\\\331.jpg', 0), ('./data\\\\mop\\\\332.jpg', 0), ('./data\\\\mop\\\\333.jpg', 0), ('./data\\\\mop\\\\335.jpg', 0), ('./data\\\\mop\\\\336.jpg', 0), ('./data\\\\mop\\\\337.jpg', 0), ('./data\\\\mop\\\\340.jpg', 0), ('./data\\\\mop\\\\342.jpg', 0), ('./data\\\\mop\\\\343.jpg', 0), ('./data\\\\mop\\\\345.jpg', 0), ('./data\\\\mop\\\\346.jpg', 0), ('./data\\\\mop\\\\349.jpg', 0), ('./data\\\\mop\\\\352.jpg', 0), ('./data\\\\mop\\\\356.jpg', 0), ('./data\\\\mop\\\\357.jpg', 0), ('./data\\\\mop\\\\358.jpg', 0), ('./data\\\\mop\\\\361.jpg', 0), ('./data\\\\mop\\\\363.jpg', 0), ('./data\\\\mop\\\\366.jpg', 0), ('./data\\\\mop\\\\367.jpg', 0), ('./data\\\\mop\\\\372.jpg', 0), ('./data\\\\mop\\\\373.jpg', 0), ('./data\\\\mop\\\\375.jpg', 0), ('./data\\\\mop\\\\376.jpg', 0), ('./data\\\\mop\\\\379.jpg', 0), ('./data\\\\mop\\\\38.jpg', 0), ('./data\\\\mop\\\\380.jpg', 0), ('./data\\\\mop\\\\381.jpg', 0), ('./data\\\\mop\\\\382.jpg', 0), ('./data\\\\mop\\\\383.jpg', 0), ('./data\\\\mop\\\\385.jpg', 0), ('./data\\\\mop\\\\39.jpg', 0), ('./data\\\\mop\\\\391.jpg', 0), ('./data\\\\mop\\\\40.jpg', 0), ('./data\\\\mop\\\\45.jpg', 0), ('./data\\\\mop\\\\51.jpg', 0), ('./data\\\\mop\\\\56.jpg', 0), ('./data\\\\mop\\\\63.jpg', 0), ('./data\\\\mop\\\\64.jpg', 0), ('./data\\\\mop\\\\71.jpg', 0), ('./data\\\\mop\\\\74.jpg', 0), ('./data\\\\mop\\\\76.jpg', 0), ('./data\\\\mop\\\\82.jpg', 0), ('./data\\\\mop\\\\9.jpg', 0), ('./data\\\\mop_dog\\\\0.jpg', 1), ('./data\\\\mop_dog\\\\12.jpg', 1), ('./data\\\\mop_dog\\\\16.jpg', 1), ('./data\\\\mop_dog\\\\19.jpg', 1), ('./data\\\\mop_dog\\\\20.jpg', 1), ('./data\\\\mop_dog\\\\201.jpg', 1), ('./data\\\\mop_dog\\\\202.jpg', 1), ('./data\\\\mop_dog\\\\21.jpg', 1), ('./data\\\\mop_dog\\\\23.jpg', 1), ('./data\\\\mop_dog\\\\230.jpg', 1), ('./data\\\\mop_dog\\\\234.jpg', 1), ('./data\\\\mop_dog\\\\24.jpg', 1), ('./data\\\\mop_dog\\\\244.jpg', 1), ('./data\\\\mop_dog\\\\25.jpg', 1), ('./data\\\\mop_dog\\\\258.jpg', 1), ('./data\\\\mop_dog\\\\26.jpg', 1), ('./data\\\\mop_dog\\\\27.jpg', 1), ('./data\\\\mop_dog\\\\281.jpg', 1), ('./data\\\\mop_dog\\\\287.jpg', 1), ('./data\\\\mop_dog\\\\299.jpg', 1), ('./data\\\\mop_dog\\\\300.jpg', 1), ('./data\\\\mop_dog\\\\302.jpg', 1), ('./data\\\\mop_dog\\\\304.jpg', 1), ('./data\\\\mop_dog\\\\305.jpg', 1), ('./data\\\\mop_dog\\\\308.jpg', 1), ('./data\\\\mop_dog\\\\309.jpg', 1), ('./data\\\\mop_dog\\\\310.jpg', 1), ('./data\\\\mop_dog\\\\311.jpg', 1), ('./data\\\\mop_dog\\\\314.jpg', 1), ('./data\\\\mop_dog\\\\315.jpg', 1), ('./data\\\\mop_dog\\\\316.jpg', 1), ('./data\\\\mop_dog\\\\319.jpg', 1), ('./data\\\\mop_dog\\\\320.jpg', 1), ('./data\\\\mop_dog\\\\321.jpg', 1), ('./data\\\\mop_dog\\\\322.jpg', 1), ('./data\\\\mop_dog\\\\33.jpg', 1), ('./data\\\\mop_dog\\\\330.jpg', 1), ('./data\\\\mop_dog\\\\331.jpg', 1), ('./data\\\\mop_dog\\\\341.jpg', 1), ('./data\\\\mop_dog\\\\342.jpg', 1), ('./data\\\\mop_dog\\\\343.jpg', 1), ('./data\\\\mop_dog\\\\344.jpg', 1), ('./data\\\\mop_dog\\\\351.jpg', 1), ('./data\\\\mop_dog\\\\354.jpg', 1), ('./data\\\\mop_dog\\\\358.jpg', 1), ('./data\\\\mop_dog\\\\359.jpg', 1), ('./data\\\\mop_dog\\\\36.jpg', 1), ('./data\\\\mop_dog\\\\362.jpg', 1), ('./data\\\\mop_dog\\\\37.jpg', 1), ('./data\\\\mop_dog\\\\370.jpg', 1), ('./data\\\\mop_dog\\\\371.jpg', 1), ('./data\\\\mop_dog\\\\374.jpg', 1), ('./data\\\\mop_dog\\\\375.jpg', 1), ('./data\\\\mop_dog\\\\379.jpg', 1), ('./data\\\\mop_dog\\\\38.jpg', 1), ('./data\\\\mop_dog\\\\380.jpg', 1), ('./data\\\\mop_dog\\\\381.jpg', 1), ('./data\\\\mop_dog\\\\385.jpg', 1), ('./data\\\\mop_dog\\\\387.jpg', 1), ('./data\\\\mop_dog\\\\388.jpg', 1), ('./data\\\\mop_dog\\\\39.jpg', 1), ('./data\\\\mop_dog\\\\391.jpg', 1), ('./data\\\\mop_dog\\\\392.jpg', 1), ('./data\\\\mop_dog\\\\393.jpg', 1), ('./data\\\\mop_dog\\\\394.jpg', 1), ('./data\\\\mop_dog\\\\395.jpg', 1), ('./data\\\\mop_dog\\\\41.jpg', 1), ('./data\\\\mop_dog\\\\42.jpg', 1), ('./data\\\\mop_dog\\\\44.jpg', 1), ('./data\\\\mop_dog\\\\5.jpg', 1), ('./data\\\\mop_dog\\\\52.jpg', 1), ('./data\\\\mop_dog\\\\57.jpg', 1), ('./data\\\\mop_dog\\\\62.jpg', 1), ('./data\\\\mop_dog\\\\68.jpg', 1), ('./data\\\\mop_dog\\\\7.jpg', 1), ('./data\\\\mop_dog\\\\70.jpg', 1), ('./data\\\\mop_dog\\\\74.jpg', 1), ('./data\\\\mop_dog\\\\79.jpg', 1), ('./data\\\\mop_dog\\\\84.jpg', 1), ('./data\\\\mop_dog\\\\85.jpg', 1), ('./data\\\\mop_dog\\\\87.jpg', 1), ('./data\\\\mop_dog\\\\89.jpg', 1), ('./data\\\\mop_dog\\\\9.jpg', 1), ('./data\\\\mop_dog\\\\91.jpg', 1), ('./data\\\\mop_dog\\\\92.jpg', 1), ('./data\\\\mop_dog\\\\97.jpg', 1)]\n"
     ]
    }
   ],
   "source": [
    "img_dir=\"./data\"\n",
    "img_test_dir=\"./data_test\"\n",
    "\n",
    "preprocessing = transforms.Compose(transforms=[\n",
    "    transforms.Resize(size=100, interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "    transforms.CenterCrop(size=50),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "imgDS = ImageFolder(root=img_dir, transform=preprocessing)\n",
    "imgTS = ImageFolder(root=img_test_dir, transform=preprocessing)\n",
    "print(imgDS.classes, imgDS.targets, imgDS.imgs, end=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3, 50, 50]) tensor([0, 1, 0, 1, 0, 0, 1, 0, 0, 1])\n",
      "torch.Size([10, 3, 50, 50]) tensor([1, 0, 1, 0, 1, 0, 0, 1, 1, 0])\n",
      "torch.Size([10, 3, 50, 50]) tensor([1, 1, 0, 1, 1, 1, 0, 1, 1, 1])\n",
      "torch.Size([10, 3, 50, 50]) tensor([1, 0, 0, 1, 1, 1, 1, 1, 0, 0])\n",
      "torch.Size([10, 3, 50, 50]) tensor([0, 1, 0, 0, 1, 0, 0, 1, 0, 0])\n",
      "torch.Size([10, 3, 50, 50]) tensor([1, 0, 0, 0, 1, 0, 0, 1, 1, 0])\n",
      "torch.Size([10, 3, 50, 50]) tensor([0, 1, 0, 1, 1, 1, 0, 1, 0, 0])\n",
      "torch.Size([10, 3, 50, 50]) tensor([0, 1, 1, 0, 1, 1, 0, 0, 0, 0])\n",
      "torch.Size([10, 3, 50, 50]) tensor([0, 1, 0, 1, 0, 1, 1, 0, 1, 0])\n",
      "torch.Size([10, 3, 50, 50]) tensor([0, 1, 0, 1, 0, 0, 1, 1, 0, 1])\n",
      "torch.Size([10, 3, 50, 50]) tensor([0, 1, 0, 1, 1, 0, 1, 0, 0, 0])\n",
      "torch.Size([10, 3, 50, 50]) tensor([1, 1, 1, 1, 1, 0, 1, 0, 1, 0])\n",
      "torch.Size([10, 3, 50, 50]) tensor([1, 0, 0, 0, 1, 1, 1, 1, 0, 1])\n",
      "torch.Size([10, 3, 50, 50]) tensor([1, 1, 0, 0, 1, 0, 1, 0, 0, 0])\n",
      "torch.Size([10, 3, 50, 50]) tensor([0, 0, 1, 1, 1, 0, 1, 1, 1, 0])\n",
      "torch.Size([10, 3, 50, 50]) tensor([0, 0, 0, 0, 1, 0, 0, 1, 0, 1])\n",
      "torch.Size([10, 3, 50, 50]) tensor([0, 0, 0, 0, 1, 1, 0, 1, 1, 1])\n",
      "torch.Size([6, 3, 50, 50]) tensor([0, 0, 0, 1, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "imgDL=DataLoader(imgDS, batch_size=10, shuffle=True, drop_last=False)\n",
    "imtTDL=DataLoader(imgTS, batch_size=10, shuffle=True, drop_last=False)\n",
    "for (img, label) in imgDL:\n",
    "    print(img.shape, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_model = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "res_model.fc = nn.Linear(in_features=512, out_features=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "ResNet                                   [3, 3]                    --\n",
       "├─Conv2d: 1-1                            [3, 64, 12, 12]           9,408\n",
       "├─BatchNorm2d: 1-2                       [3, 64, 12, 12]           128\n",
       "├─ReLU: 1-3                              [3, 64, 12, 12]           --\n",
       "├─MaxPool2d: 1-4                         [3, 64, 6, 6]             --\n",
       "├─Sequential: 1-5                        [3, 64, 6, 6]             --\n",
       "│    └─BasicBlock: 2-1                   [3, 64, 6, 6]             --\n",
       "│    │    └─Conv2d: 3-1                  [3, 64, 6, 6]             36,864\n",
       "│    │    └─BatchNorm2d: 3-2             [3, 64, 6, 6]             128\n",
       "│    │    └─ReLU: 3-3                    [3, 64, 6, 6]             --\n",
       "│    │    └─Conv2d: 3-4                  [3, 64, 6, 6]             36,864\n",
       "│    │    └─BatchNorm2d: 3-5             [3, 64, 6, 6]             128\n",
       "│    │    └─ReLU: 3-6                    [3, 64, 6, 6]             --\n",
       "│    └─BasicBlock: 2-2                   [3, 64, 6, 6]             --\n",
       "│    │    └─Conv2d: 3-7                  [3, 64, 6, 6]             36,864\n",
       "│    │    └─BatchNorm2d: 3-8             [3, 64, 6, 6]             128\n",
       "│    │    └─ReLU: 3-9                    [3, 64, 6, 6]             --\n",
       "│    │    └─Conv2d: 3-10                 [3, 64, 6, 6]             36,864\n",
       "│    │    └─BatchNorm2d: 3-11            [3, 64, 6, 6]             128\n",
       "│    │    └─ReLU: 3-12                   [3, 64, 6, 6]             --\n",
       "├─Sequential: 1-6                        [3, 128, 3, 3]            --\n",
       "│    └─BasicBlock: 2-3                   [3, 128, 3, 3]            --\n",
       "│    │    └─Conv2d: 3-13                 [3, 128, 3, 3]            73,728\n",
       "│    │    └─BatchNorm2d: 3-14            [3, 128, 3, 3]            256\n",
       "│    │    └─ReLU: 3-15                   [3, 128, 3, 3]            --\n",
       "│    │    └─Conv2d: 3-16                 [3, 128, 3, 3]            147,456\n",
       "│    │    └─BatchNorm2d: 3-17            [3, 128, 3, 3]            256\n",
       "│    │    └─Sequential: 3-18             [3, 128, 3, 3]            8,448\n",
       "│    │    └─ReLU: 3-19                   [3, 128, 3, 3]            --\n",
       "│    └─BasicBlock: 2-4                   [3, 128, 3, 3]            --\n",
       "│    │    └─Conv2d: 3-20                 [3, 128, 3, 3]            147,456\n",
       "│    │    └─BatchNorm2d: 3-21            [3, 128, 3, 3]            256\n",
       "│    │    └─ReLU: 3-22                   [3, 128, 3, 3]            --\n",
       "│    │    └─Conv2d: 3-23                 [3, 128, 3, 3]            147,456\n",
       "│    │    └─BatchNorm2d: 3-24            [3, 128, 3, 3]            256\n",
       "│    │    └─ReLU: 3-25                   [3, 128, 3, 3]            --\n",
       "├─Sequential: 1-7                        [3, 256, 2, 2]            --\n",
       "│    └─BasicBlock: 2-5                   [3, 256, 2, 2]            --\n",
       "│    │    └─Conv2d: 3-26                 [3, 256, 2, 2]            294,912\n",
       "│    │    └─BatchNorm2d: 3-27            [3, 256, 2, 2]            512\n",
       "│    │    └─ReLU: 3-28                   [3, 256, 2, 2]            --\n",
       "│    │    └─Conv2d: 3-29                 [3, 256, 2, 2]            589,824\n",
       "│    │    └─BatchNorm2d: 3-30            [3, 256, 2, 2]            512\n",
       "│    │    └─Sequential: 3-31             [3, 256, 2, 2]            33,280\n",
       "│    │    └─ReLU: 3-32                   [3, 256, 2, 2]            --\n",
       "│    └─BasicBlock: 2-6                   [3, 256, 2, 2]            --\n",
       "│    │    └─Conv2d: 3-33                 [3, 256, 2, 2]            589,824\n",
       "│    │    └─BatchNorm2d: 3-34            [3, 256, 2, 2]            512\n",
       "│    │    └─ReLU: 3-35                   [3, 256, 2, 2]            --\n",
       "│    │    └─Conv2d: 3-36                 [3, 256, 2, 2]            589,824\n",
       "│    │    └─BatchNorm2d: 3-37            [3, 256, 2, 2]            512\n",
       "│    │    └─ReLU: 3-38                   [3, 256, 2, 2]            --\n",
       "├─Sequential: 1-8                        [3, 512, 1, 1]            --\n",
       "│    └─BasicBlock: 2-7                   [3, 512, 1, 1]            --\n",
       "│    │    └─Conv2d: 3-39                 [3, 512, 1, 1]            1,179,648\n",
       "│    │    └─BatchNorm2d: 3-40            [3, 512, 1, 1]            1,024\n",
       "│    │    └─ReLU: 3-41                   [3, 512, 1, 1]            --\n",
       "│    │    └─Conv2d: 3-42                 [3, 512, 1, 1]            2,359,296\n",
       "│    │    └─BatchNorm2d: 3-43            [3, 512, 1, 1]            1,024\n",
       "│    │    └─Sequential: 3-44             [3, 512, 1, 1]            132,096\n",
       "│    │    └─ReLU: 3-45                   [3, 512, 1, 1]            --\n",
       "│    └─BasicBlock: 2-8                   [3, 512, 1, 1]            --\n",
       "│    │    └─Conv2d: 3-46                 [3, 512, 1, 1]            2,359,296\n",
       "│    │    └─BatchNorm2d: 3-47            [3, 512, 1, 1]            1,024\n",
       "│    │    └─ReLU: 3-48                   [3, 512, 1, 1]            --\n",
       "│    │    └─Conv2d: 3-49                 [3, 512, 1, 1]            2,359,296\n",
       "│    │    └─BatchNorm2d: 3-50            [3, 512, 1, 1]            1,024\n",
       "│    │    └─ReLU: 3-51                   [3, 512, 1, 1]            --\n",
       "├─AdaptiveAvgPool2d: 1-9                 [3, 512, 1, 1]            --\n",
       "├─Linear: 1-10                           [3, 3]                    1,539\n",
       "==========================================================================================\n",
       "Total params: 11,178,051\n",
       "Trainable params: 11,178,051\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 84.51\n",
       "==========================================================================================\n",
       "Input size (MB): 0.02\n",
       "Forward/backward pass size (MB): 1.53\n",
       "Params size (MB): 44.71\n",
       "Estimated Total Size (MB): 46.26\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model=res_model, input_size=(3,3,24,24))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mathn\\.conda\\envs\\Torch_PY38\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n",
      "[1/100] Loss: 1.298, Accuracy: 0.573: 100%|██████████| 18/18 [00:03<00:00,  4.88it/s]\n",
      "[2/100] Loss: 0.543, Accuracy: 0.801: 100%|██████████| 18/18 [00:03<00:00,  5.16it/s]\n",
      "[3/100] Loss: 0.380, Accuracy: 0.894: 100%|██████████| 18/18 [00:03<00:00,  5.34it/s]\n",
      "[4/100] Loss: 0.401, Accuracy: 0.865: 100%|██████████| 18/18 [00:03<00:00,  5.40it/s]\n",
      "[5/100] Loss: 0.294, Accuracy: 0.877: 100%|██████████| 18/18 [00:03<00:00,  5.39it/s]\n",
      "[6/100] Loss: 0.350, Accuracy: 0.899: 100%|██████████| 18/18 [00:03<00:00,  5.39it/s]\n",
      "[7/100] Loss: 0.270, Accuracy: 0.920: 100%|██████████| 18/18 [00:03<00:00,  5.13it/s]\n",
      "[8/100] Loss: 0.314, Accuracy: 0.905: 100%|██████████| 18/18 [00:03<00:00,  5.16it/s]\n",
      "[9/100] Loss: 0.156, Accuracy: 0.958: 100%|██████████| 18/18 [00:03<00:00,  5.16it/s]\n",
      "[10/100] Loss: 0.302, Accuracy: 0.897: 100%|██████████| 18/18 [00:03<00:00,  5.07it/s]\n",
      "[11/100] Loss: 0.437, Accuracy: 0.902: 100%|██████████| 18/18 [00:03<00:00,  5.04it/s]\n",
      "[12/100] Loss: 0.354, Accuracy: 0.918: 100%|██████████| 18/18 [00:03<00:00,  4.99it/s]\n",
      "[13/100] Loss: 0.255, Accuracy: 0.933: 100%|██████████| 18/18 [00:03<00:00,  4.97it/s]\n",
      "[14/100] Loss: 0.190, Accuracy: 0.973: 100%|██████████| 18/18 [00:03<00:00,  5.04it/s]\n",
      "[15/100] Loss: 0.094, Accuracy: 0.984: 100%|██████████| 18/18 [00:03<00:00,  5.00it/s]\n",
      "[16/100] Loss: 0.152, Accuracy: 0.947: 100%|██████████| 18/18 [00:03<00:00,  5.00it/s]\n",
      "[17/100] Loss: 0.124, Accuracy: 0.941: 100%|██████████| 18/18 [00:03<00:00,  5.01it/s]\n",
      "[18/100] Loss: 0.153, Accuracy: 0.961: 100%|██████████| 18/18 [00:03<00:00,  4.99it/s]\n",
      "[19/100] Loss: 0.082, Accuracy: 0.985: 100%|██████████| 18/18 [00:03<00:00,  5.04it/s]\n",
      "[20/100] Loss: 0.060, Accuracy: 0.986: 100%|██████████| 18/18 [00:03<00:00,  5.06it/s]\n",
      "[21/100] Loss: 0.159, Accuracy: 0.965: 100%|██████████| 18/18 [00:03<00:00,  5.00it/s]\n",
      "[22/100] Loss: 0.030, Accuracy: 0.992: 100%|██████████| 18/18 [00:03<00:00,  5.02it/s]\n",
      "[23/100] Loss: 0.252, Accuracy: 0.870: 100%|██████████| 18/18 [00:03<00:00,  5.00it/s]\n",
      "[24/100] Loss: 0.226, Accuracy: 0.949: 100%|██████████| 18/18 [00:03<00:00,  5.04it/s]\n",
      "[25/100] Loss: 0.037, Accuracy: 1.000: 100%|██████████| 18/18 [00:03<00:00,  5.03it/s]\n",
      "[26/100] Loss: 0.006, Accuracy: 1.000: 100%|██████████| 18/18 [00:03<00:00,  5.00it/s]\n",
      "[27/100] Loss: 0.009, Accuracy: 1.000: 100%|██████████| 18/18 [00:03<00:00,  4.81it/s]\n",
      "[28/100] Loss: 0.003, Accuracy: 1.000: 100%|██████████| 18/18 [00:03<00:00,  4.95it/s]\n",
      "[29/100] Loss: 0.023, Accuracy: 0.983: 100%|██████████| 18/18 [00:03<00:00,  5.05it/s]\n",
      "[30/100] Loss: 0.065, Accuracy: 0.994: 100%|██████████| 18/18 [00:03<00:00,  5.06it/s]\n",
      "[31/100] Loss: 0.041, Accuracy: 0.994: 100%|██████████| 18/18 [00:03<00:00,  5.00it/s]\n",
      "[32/100] Loss: 0.069, Accuracy: 0.983: 100%|██████████| 18/18 [00:03<00:00,  5.06it/s]\n",
      "[33/100] Loss: 0.049, Accuracy: 0.975: 100%|██████████| 18/18 [00:03<00:00,  4.96it/s]\n",
      "[34/100] Loss: 0.097, Accuracy: 0.971: 100%|██████████| 18/18 [00:03<00:00,  5.06it/s]\n",
      "[35/100] Loss: 0.215, Accuracy: 0.931: 100%|██████████| 18/18 [00:03<00:00,  4.95it/s]\n",
      "[36/100] Loss: 0.149, Accuracy: 0.960: 100%|██████████| 18/18 [00:03<00:00,  5.01it/s]\n",
      "[37/100] Loss: 0.085, Accuracy: 0.982: 100%|██████████| 18/18 [00:03<00:00,  4.68it/s]\n",
      "[38/100] Loss: 0.111, Accuracy: 0.963: 100%|██████████| 18/18 [00:03<00:00,  4.76it/s]\n",
      "[39/100] Loss: 0.110, Accuracy: 0.976: 100%|██████████| 18/18 [00:03<00:00,  4.91it/s]\n",
      "[40/100] Loss: 0.022, Accuracy: 1.000: 100%|██████████| 18/18 [00:03<00:00,  4.72it/s]\n",
      "[41/100] Loss: 0.096, Accuracy: 0.969: 100%|██████████| 18/18 [00:03<00:00,  4.97it/s]\n",
      "[42/100] Loss: 0.118, Accuracy: 0.986: 100%|██████████| 18/18 [00:03<00:00,  4.97it/s]\n",
      "[43/100] Loss: 0.034, Accuracy: 0.994: 100%|██████████| 18/18 [00:03<00:00,  4.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 42\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(res_model.parameters(), lr=1e-3)\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=10, verbose=True)\n",
    "\n",
    "n_epoch = 100\n",
    "for epoch in range(n_epoch):\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    pbar = tqdm(enumerate(imgDL), total=len(imgDL))\n",
    "    for i, data in pbar:\n",
    "        inputs, labels = data\n",
    "        outputs = res_model(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        acc = multiclass_accuracy(outputs, labels, num_classes=3)\n",
    "        running_acc += acc\n",
    "\n",
    "        if i % 10 == 9:\n",
    "            pbar.set_description(f\"[{epoch+1}/{n_epoch}] Loss: {running_loss/10:.3f}, Accuracy: {running_acc/10:.3f}\")\n",
    "            running_loss = 0.0\n",
    "            running_acc = 0.0\n",
    "            \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in imgDL:\n",
    "            images, labels = data\n",
    "            outputs = res_model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    current_accuracy = correct / total\n",
    "    \n",
    "    scheduler.step(loss)\n",
    "    if scheduler.num_bad_epochs >= scheduler.patience:\n",
    "        print(f\"Early stopping at epoch {epoch}\")\n",
    "        break\n",
    "\n",
    "# 학습된 모델 저장\n",
    "torch.save(res_model.state_dict(), \"./resnet18.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 정확도 : 71.60493827160494%\n"
     ]
    }
   ],
   "source": [
    "# 학습된 모델 불러오기\n",
    "res_model.load_state_dict(torch.load(\"./resnet18.pth\"))\n",
    "\n",
    "# 학습된 모델 평가\n",
    "res_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in imtTDL:\n",
    "        images, labels = data\n",
    "        outputs = res_model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print(f\"Test 정확도 : {100*correct/total}%\")\n",
    "\n",
    "# 학습된 모델 사용하기\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 테스트 이미지 불러오기\n",
    "test_img = ImageFolder(root=img_dir, transform=preprocessing)\n",
    "test_loader = DataLoader(test_img, batch_size=4, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Torch_PY38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
