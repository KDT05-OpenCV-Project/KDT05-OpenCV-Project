{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as transforms\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((50,50)),  # 원하는 크기로 이미지 리사이즈\n",
    "    transforms.ToTensor()  # 이미지를 텐서로 변환\n",
    "])\n",
    "\n",
    "# ImageFolder 데이터셋 생성\n",
    "data = ImageFolder(root=\"./data\", transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(data, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3, 50, 50]) torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "images, labels = next(iter(data_loader))\n",
    "print(images.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN 모델클래스 생성\n",
    "class Mob_Dog(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Mob_Dog, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 9 * 9, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 9 * 9)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 객체 생성, 옵티마이저 생성\n",
    "model = Mob_Dog()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [10/18], Loss: 0.6765: 100%|██████████| 18/18 [00:00<00:00, 35.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 53 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Step [10/18], Loss: 0.6839: 100%|██████████| 18/18 [00:00<00:00, 49.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 53 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Step [10/18], Loss: 0.6845: 100%|██████████| 18/18 [00:00<00:00, 49.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 53 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Step [10/18], Loss: 0.6856: 100%|██████████| 18/18 [00:00<00:00, 52.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 53 %\n",
      "No improvement in accuracy for 3 epochs. Training stopped.\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# 학습 진행\n",
    "best_accuracy = 0.0\n",
    "no_improvement_count = 0\n",
    "for epoch in range(10):\n",
    "    running_loss = 0.0\n",
    "    pbar = tqdm(enumerate(data_loader), total=len(data_loader))\n",
    "    for i, data in pbar:\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        if i % 10 == 9:\n",
    "            pbar.set_description(f'Epoch [{epoch + 1}/{10}], Step [{i + 1}/{len(data_loader)}], Loss: {running_loss / 10:.4f}')\n",
    "            running_loss = 0.0\n",
    "            \n",
    "    # 모델 평가\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in data_loader:\n",
    "            images, labels = data\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    epoch_accuracy = correct / total\n",
    "    print('Accuracy of the network on the 10000 test images: %d %%' % (100 * epoch_accuracy))\n",
    "    \n",
    "    # Scheduler로 정확도 변화를 관찰하여 학습 조기 종료\n",
    "    if epoch_accuracy > best_accuracy:\n",
    "        best_accuracy = epoch_accuracy\n",
    "        no_improvement_count = 0\n",
    "    else:\n",
    "        no_improvement_count += 1\n",
    "        if no_improvement_count >= 3:\n",
    "            print(f'No improvement in accuracy for {no_improvement_count} epochs. Training stopped.')\n",
    "            break\n",
    "\n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 저장\n",
    "torch.save(model.state_dict(), 'mob_dog.pth')\n",
    "\n",
    "# 모델 로드\n",
    "model = Mob_Dog()\n",
    "model.load_state_dict(torch.load('mob_dog.pth'))\n",
    "model.eval()\n",
    "\n",
    "# 이미지 예측\n",
    "img = cv2.imread('./data/mop_dog/0.jpg')\n",
    "img = cv2.resize(img, (50, 50))\n",
    "#img = img / 255.0\n",
    "img = np.transpose(img, (2, 0, 1))\n",
    "img = torch.Tensor(img)\n",
    "img = img.unsqueeze(0)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(img)\n",
    "    _, predicted = torch.max(output.data, 1)\n",
    "predicted # 이런 젠장, 걸레라고 나온다 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Torch_PY38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
